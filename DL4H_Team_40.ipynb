{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justintran12/CS598-DLH-FinalProject/blob/main/DL4H_Team_40.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Notebook to Google Drive\n",
        "\n",
        "Note: not needed anymore, use gdown instead to download the public file from google drive\n",
        "\n",
        "Upload the data, pretrianed model, figures, etc to your Google Drive, then mount this notebook to Google Drive. After that, you can access the resources freely.\n",
        "\n",
        "Instruction: https://colab.research.google.com/notebooks/io.ipynb\n",
        "\n",
        "Example: https://colab.research.google.com/drive/1srw_HFWQ2SMgmWIawucXfusGzrj1_U0q\n",
        "\n",
        "Video: https://www.youtube.com/watch?v=zc8g8lGcwQU"
      ],
      "metadata": {
        "id": "dlv6knX04FiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# not needed anymore, use gdown instead to download the public file from google drive\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "'''"
      ],
      "metadata": {
        "id": "sfk8Zrul_E8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video Link\n",
        "\n",
        "https://drive.google.com/file/d/1fnz2Jv7rojMCsDmE_PFbaQQ5xiZ_2PEQ/view?usp=drive_link"
      ],
      "metadata": {
        "id": "z4F-0fPHZ9Xi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "  The original paper addresses the problem of cancer type detection through inferring cancer marker genes. By solving this problem, cancer will be more easily detected in the early stages, leading to drastically improved survivability rates. The challenge is that it is difficult to take the tissue of origin into account when developing models, due to loss of accuracy when doing so. Also, it is time and resource intensive to train a model with many layers that is able to detect cancer marker genes accurately.\n",
        "\n",
        "  Current state of the art methods include using a fully connected deep neural network (Ahn, et al), using a k-nearest neighbor alrgorithm with a genetic algorithm for gene selection (Li et al), convolutional neural network (CNN) model with a 2D mapping of the gene expression samples as input matrices (Lyu et al). The KNN model achieved greater than 90% accuracy for predicting 31 cancer types. The CNN model achieved greater than 95% accuracy for 33 The Cancer Genome Atlas (TCGA) cancer types.\n",
        "\n",
        "  The original paper proposed 3 different CNN models, a 1D-CNN model, 2D-Vanilla-CNN model, and a 2D-Hybrid-CNN model. Each model uses just one convolution layer.\n",
        "  \n",
        "  The 1D-CNN model takes a 1-D vector as input and applies 1-D convolution kernels. The stride of the convolution and the kernel size are the same in order to capture only the global featrues in the data, since the authors were not sure that there were any correlations between neighboring gene expressions.\n",
        "\n",
        "  The 2D-Vanilla-CNN takes in a 2-D matrix and is similar to commonly used CNNs that take in image data and attempt to capture local features. Since a 2-D matrix is an input, the gene expression data is reshpaed into a 100 by 71 matrix.\n",
        "\n",
        "  The 2D-Hybrid-CNN model takes in a 2-D matrix as input, but uses 1-D convolution kernels. One kernel slides horizontally over each column and the other slides vertically over each row. This hybrid model has the positive benefits from both the 1D-CNN and the 2D-Vanilla, it can take in 2-D inputs, while using simple 1-D kernels. The original authors also believed this model would capture more global unstructured features.\n",
        "\n",
        "  For each model, ReLU is used as the activation function, the input is first fed into a convolution layer, then a pooling layer, then a fully connected layer, then a softmax prediction layer to generate the output. For the Hybrid model, the outputs of the pooling layer are concatenated together before being fed into the fully connected layer.\n",
        "\n",
        "  Categorical Cross Entropy is the loss function, Categorical accuracy is training metric and the Adam optimizer were selected for all 3 CNN models\n",
        "\n",
        "  These 3 models proposed by this paper, are able to achieve similar accuracy metrics compared to a more complicated multi-layer model while using less resources while training and tuning hyperparameters. Having less layers also can prevent overfitting, especially in this case, as there are limited samples relative to the number of parameters.\n",
        "\n",
        "  The 1D-CNN and 2D-Hybrid-CNN achieved comparable accuracy (95.7%), which improves the result (95.6%) of the 2D-3Layer-CNN. Also, the 1D-CNN model uses significantly less hyperparameters (200 thousand) compared to the 2D-3Layer-CNN (26 million).\n",
        "\n",
        "  The contribution of this paper is the three lighter models that have comparable accuracy metrics to the more traditional multi-layer models. The lighter models use less hyperparameters, take less time and resources to train, and are less prone to overfitting. Also when taking tissue of origin into account, the three proposed models have accetable accuracy results.\n"
      ],
      "metadata": {
        "id": "MQ0sNuMePBXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scope of Reproducibility:\n",
        "\n",
        "1.   Hypothesis 1: Proposed single convolution layer CNN models can achieve similar or better accuracy metrics compared to traditional multi-layer CNN models.\n",
        "\n",
        "  Experiment: All three CNN models were trained with all 10,340 tumor samples initially. The loss function values over 50 epochs and categorical accuracy were measured. I will use 1 epoch in this reproduction as an example of the training, as multiple epochs takes too long to finish training. An 80-20% train-validation split was used.\n",
        "\n",
        "2.   Hypothesis 2: Proposed single convolution layer CNN models can achieve acceptable accuracy metrics when taking tissue of origin into account.\n",
        "\n",
        "  Experiment: Similar to experiment for hypothesis 1 except a new label is introduced in the prediction layer which takes all normal samples regardless of their original tissue type designation. This 34th node removes the trace of tissue of origins from cancer samples.\n",
        "\n"
      ],
      "metadata": {
        "id": "uygL9tTPSVHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology"
      ],
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment\n",
        "\n",
        "Use Python 3.\n",
        "\n",
        "sklearn version 1.2.2, keras packages needed. Do not install scikeras."
      ],
      "metadata": {
        "id": "-oJUceocNvBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run the following if needed\n",
        "#pip install keras\n",
        "#pip install sklearn\n",
        "# DO NOT INSTALL SCIKERAS\n",
        "#pip install scikeras\n",
        "\n",
        "# sklearn version should be 1.2.2\n",
        "#import sklearn; print(sklearn.__version__)"
      ],
      "metadata": {
        "id": "Y3t71BT1yYBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages and dependencies\n",
        "import gdown\n",
        "import numpy as np\n",
        "import time\n",
        "from google.colab import drive\n",
        "\n",
        "import pickle\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, Input, LeakyReLU, BatchNormalization, concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, auc, average_precision_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from collections import Counter\n",
        "#from scikeras.wrappers import KerasClassifier\n",
        "#import keras"
      ],
      "metadata": {
        "id": "yu61Jp1xrnKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Data\n",
        "\n",
        "  The data is real-world, pan-cancer RNA-Seq data taken from The Cancer Genome Atlas through an R package called TCGABiolinks in 2018. There is no direct link to the raw data in the paper. The dataset contains 10340 samples for 33 cancer types and 714 samples for 23 normal tissues. The paper pre-processed the data and stored the post-processed data in pickle files for the 33 class data and 34 class data (33 classes plus normal). The pickle files are available for download from the author's github under the README file (Mostavi) [2], not the chenlabgccr github. For my reproduction, I downloaded the pickle files and stored them in the same directory as this notebook in Google Drives.\n",
        "\n",
        "  In the data pre-process step, genes with low information burden (mean < 0.5 and standard deviation < 0.8) were removed across all samples. This was done to remove noise-sensitive features from the dataset. 7091 genes remained after filtering in this pre-process step. Afterwards, nine zeros were added to the dataset to round the input dimension to 7100 to allow for easier modeling of the data. I added notes in the below code to show how this was done. The indices of the samples to use were already included in the pickle file by the author.\n",
        "\n",
        "  The code to load the data for the 33 class case and the 34 class case is slightly different, so I just separated them into two functions for easier use.\n",
        "\n",
        "  The cross validation split is 80-20% for training and validation."
      ],
      "metadata": {
        "id": "2NbPHUTMbkD3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZScZNbROw-N"
      },
      "outputs": [],
      "source": [
        "# Loading the data for 33 class and 34 class\n",
        "def load_processed_data_33_Class(processed_data_dir_1, processed_data_dir_2):\n",
        "\n",
        "  ## load the pickle files\n",
        "  A = open(processed_data_dir_2, 'rb')\n",
        "  [dropped_genes_final, dropped_gene_name, dropped_Ens_id, samp_id_new, diag_name_new,\n",
        "  project_ids_new] = pd.read_pickle(A)\n",
        "  A.close()\n",
        "\n",
        "  f = open(processed_data_dir_1 , 'rb')\n",
        "  [_, _, _, _, remain_cancer_ids_ind, remain_normal_ids_ind] = pd.read_pickle(f)\n",
        "  f.close()\n",
        "\n",
        "  ## embedding labels\n",
        "  # integer encode\n",
        "  label_encoder = LabelEncoder()\n",
        "  integer_encoded = label_encoder.fit_transform(project_ids_new)\n",
        "  # binary encode\n",
        "  onehot_encoder = OneHotEncoder(sparse=False)\n",
        "  integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "  onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "\n",
        "  ## filter out the dropped genes\n",
        "  X_cancer_samples =dropped_genes_final.iloc[:,remain_cancer_ids_ind].T.values\n",
        "  X_normal_samples = dropped_genes_final.iloc[:,remain_normal_ids_ind].T.values\n",
        "  onehot_encoded_cancer_samples = onehot_encoded[remain_cancer_ids_ind]\n",
        "  onehot_encoded_normal_samples = onehot_encoded[remain_normal_ids_ind]\n",
        "\n",
        "  ## add nine zeros to the end of each sample\n",
        "  X_cancer_samples_mat = np.concatenate((X_cancer_samples,np.zeros((len(X_cancer_samples),9))),axis=1)\n",
        "  X_cancer_samples_mat = np.reshape(X_cancer_samples_mat, (-1, 71, 100))\n",
        "\n",
        "  input_Xs = X_cancer_samples_mat\n",
        "  y_s = project_ids_new[remain_cancer_ids_ind]\n",
        "\n",
        "  ## This line is useful when only one fold training is needed\n",
        "  x_train, x_test, y_train, y_test = train_test_split(X_cancer_samples_mat, onehot_encoded_cancer_samples,\n",
        "                                                      stratify= onehot_encoded_cancer_samples,\n",
        "                                                      test_size=0.25, random_state=42)\n",
        "\n",
        "  img_rows, img_cols = len(x_test[0]), len(x_test[0][0])\n",
        "\n",
        "  # hybrid model flips the rows and cols\n",
        "  img_rows_hyb, img_cols_hyb = len(x_test[0][0]), len(x_test[0])\n",
        "  num_classes = len(y_train[0])\n",
        "\n",
        "  return input_Xs, y_s, img_rows, img_cols, num_classes, img_rows_hyb, img_cols_hyb, x_train, x_test, y_train, y_test\n",
        "\n",
        "def load_processed_data_34_Class(processed_data_dir_1, processed_data_dir_2):\n",
        "  A = open(processed_data_dir_2, 'rb')\n",
        "  [dropped_genes_final, dropped_gene_name, dropped_Ens_id, samp_id_new, diag_name_new,\n",
        "  project_ids_new] = pd.read_pickle(A)\n",
        "  A.close()\n",
        "\n",
        "  f = open(processed_data_dir_1, 'rb')\n",
        "  [_, _, _, _, remain_cancer_ids_ind, remain_normal_ids_ind] = pd.read_pickle(f)\n",
        "  f.close()\n",
        "\n",
        "  X_cancer_samples = dropped_genes_final.iloc[:,remain_cancer_ids_ind].T.values\n",
        "  X_normal_samples = dropped_genes_final.iloc[:,remain_normal_ids_ind].T.values\n",
        "\n",
        "  name_cancer_samples = project_ids_new[remain_cancer_ids_ind]\n",
        "  name_normal_samples = ['Normal Samples'] *len(X_normal_samples)\n",
        "\n",
        "  X_cancer_samples_34 = np.concatenate((X_cancer_samples,X_normal_samples))\n",
        "  X_names = np.concatenate((name_cancer_samples,name_normal_samples))\n",
        "  X_cancer_samples_mat = np.concatenate((X_cancer_samples_34,np.zeros((len(X_cancer_samples_34),9))),axis=1)\n",
        "  X_cancer_samples_mat = np.reshape(X_cancer_samples_mat, (-1, 71, 100))\n",
        "\n",
        "  input_Xs = X_cancer_samples_mat\n",
        "  y_s = X_names\n",
        "\n",
        "  img_rows, img_cols = len(input_Xs[0][0]), len(input_Xs[0])\n",
        "  num_classes = len(set(y_s))\n",
        "\n",
        "  return input_Xs, X_cancer_samples_34, y_s, img_rows, img_cols, num_classes\n",
        "\n",
        "def load_processed_data_HP_Tuning(processed_data_dir_1, processed_data_dir_2):\n",
        "  # X_cancer_samples_mat same from load_processed_data_33_Class\n",
        "  pass\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the preprocessed data via gdown\n",
        "url_1 = 'https://drive.google.com/file/d/1RVdIFcMYJyd1_PyZLO0HUBnmprPQlVUK/view?usp=sharing'\n",
        "url_2 = 'https://drive.google.com/file/d/1tFlZU7hDIvB_6daxc1UPPj-7j8MMq1Z3/view?usp=sharing'\n",
        "output_1 = 'TCGA_new_pre_first.pckl'\n",
        "output_2 = 'TCGA_new_pre_second.pckl'\n",
        "gdown.download(url=url_1, output=output_1, fuzzy=True)\n",
        "gdown.download(url=url_2, output=output_2, fuzzy=True)\n",
        "input_Xs_33, y_s_33, img_rows_33, img_cols_33, num_classes_33, img_rows_hyb_33, img_cols_hyb_33, x_train_HP, x_test_HP, y_train_HP, y_test_HP = load_processed_data_33_Class(output_1, output_2)\n",
        "input_Xs_34, X_cancer_samples_34, y_s_34, img_rows_34, img_cols_34, num_classes_34 = load_processed_data_34_Class(output_1, output_2)\n",
        "\n",
        "'''\n",
        "# getting the data via google drive mounting method\n",
        "processed_data_dir_1 = '/content/drive/My Drive/Colab Notebooks/TCGA_new_pre_first.pckl'\n",
        "processed_data_dir_2 = '/content/drive/My Drive/Colab Notebooks/TCGA_new_pre_second.pckl'\n",
        "input_Xs_33, y_s_33, img_rows_33, img_cols_33, num_classes_33, img_rows_hyb_33, img_cols_hyb_33, x_train_HP, x_test_HP, y_train_HP, y_test_HP = load_processed_data_33_Class(processed_data_dir_1, processed_data_dir_2)\n",
        "input_Xs_34, X_cancer_samples_34, y_s_34, img_rows_34, img_cols_34, num_classes_34 = load_processed_data_34_Class(processed_data_dir_1, processed_data_dir_2)\n",
        "'''"
      ],
      "metadata": {
        "id": "cjwRUcn7Q0kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##   Model\n",
        "\n",
        "  Original Paper Citation: See [1] in References section.\n",
        "\n",
        "  Original Paper GitHub Repo: https://github.com/chenlabgccri/CancerTypePrediction\n",
        "\n",
        "\n",
        "  The model architecture parameters were found from hyperparameter training tuned via Grid Search method. The dense layer size, number and size of kernels, and the stride of kernels were tuned using this method. For the 1D-CNN model, the stride was set to the same length as the kernel size in order to only capture global features. All three models proposed in the paper only use 1 convolution layer.\n",
        "\n",
        "  The 1D-CNN takes in a 1D vector representing gene expressions as input and applies 1D convolution kernels to the input. The output of the convolution layer is input to a max pooling layer, then a fully-connected (FC) layer with ReLU as the activation function, then the prediction layer which uses softmax as the activation function.\n",
        "\n",
        "  The 2D-Vanilla-CNN takes in a 2D matrix input similar to an image. The input gene expression was reshaped into 2D space before being fed into the model. The 2D CNN includes the convolutional layer with the 2D kernel, a maxpooling layer, a FC layer, and a prediction layer with similar activation functions as the 1D-CNN model. In this model, the kernel stride was tuned from the hyperparameter training in order to best capture local features.\n",
        "\n",
        "  The Hybrid-CNN takes in a 2D matrix input similar to the Vanilla-CNN, but uses two 1D kernels that slide across the rows and columns of the input separately. The outputs of the two 1D kernels are then passed through a maxpooling layer, then concatenated and fed into the FC and prediction layers with similar activation functions as the 1D-CNN model. The authors of the original paper believed this design can capture more global unstructured features in the input gene expression.\n",
        "\n",
        "  For every model, categorical_crossentropy loss function, and the adam optimzer were used. Categorical_accuracy was used as the main training metric used.\n",
        "\n",
        "  The original paper's github replicated the model code in seperate files for each model. I just made each model a class for re-usability. The only issue is that the 2D-Vanilla model is slightly different (stride used is different) for the 33 class than the 34 class, so I had two separate model classes for the 2D-Vanilla 33 class case and the 34 class case.\n"
      ],
      "metadata": {
        "id": "3muyDPFPbozY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining models\n",
        "class One_CNN():\n",
        "  # use this class to define your model\n",
        "  def __init__(self, input_shape, num_classes):\n",
        "    self.model = Sequential()\n",
        "    ## *********** First layer Conv\n",
        "    self.model.add(Conv2D(32, kernel_size=(1, 71), strides=(1, 1),\n",
        "              input_shape=input_shape))\n",
        "    self.model.add(Activation('relu'))\n",
        "    self.model.add(MaxPooling2D(1, 2))\n",
        "    ## ********* Classification layer\n",
        "    self.model.add(Flatten())\n",
        "    self.model.add(Dense(128, activation='relu'))\n",
        "    self.model.add(Dense(num_classes, activation='softmax'))\n",
        "    self.model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer='adam',\n",
        "                      metrics=['categorical_accuracy'])\n",
        "\n",
        "class Vanilla_33():\n",
        "  # use this class to define your model\n",
        "  def __init__(self, input_shape, num_classes):\n",
        "    self.model = Sequential()\n",
        "    ## *********** First layer Conv\n",
        "    self.model.add(Conv2D(32, kernel_size=(10, 10), strides=(1, 1),\n",
        "              input_shape=input_shape))\n",
        "    self.model.add(Activation('relu'))\n",
        "    self.model.add(MaxPooling2D(2, 2))\n",
        "    ## ********* Classification layer\n",
        "    self.model.add(Flatten())\n",
        "    self.model.add(Dense(128, activation='relu'))\n",
        "    self.model.add(Dense(num_classes, activation='softmax'))\n",
        "    self.model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer='adam',\n",
        "                      metrics=['categorical_accuracy'])\n",
        "\n",
        "class Hybrid():\n",
        "  # use this class to define your model\n",
        "  def __init__(self, input_img, num_classes):\n",
        "    tower_1 = Conv2D(32, (1, 71), activation='relu')(input_img)\n",
        "    tower_1 = MaxPooling2D(1, 2)(tower_1)\n",
        "    tower_1 = Flatten()(tower_1)\n",
        "\n",
        "    tower_2 = Conv2D(32, (100, 1), activation='relu')(input_img)\n",
        "    tower_2 = MaxPooling2D(1, 2)(tower_2)\n",
        "    tower_2 = Flatten()(tower_2)\n",
        "\n",
        "    output = concatenate([tower_1, tower_2], axis=1)\n",
        "    out1 = Dense(128, activation='relu')(output)\n",
        "    last_layer = Dense(num_classes, activation='softmax')(out1)\n",
        "    # typo with original code, should be inputs and outputs not input and output\n",
        "    self.model = Model(inputs=[input_img], outputs=last_layer)\n",
        "    self.model.output_shape\n",
        "\n",
        "    self.model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['categorical_accuracy'])\n",
        "\n",
        "class Vanilla_34():\n",
        "  # use this class to define your model\n",
        "  def __init__(self, input_shape, num_classes):\n",
        "    self.model = Sequential()\n",
        "    ## *********** First layer Conv\n",
        "    self.model.add(Conv2D(32, kernel_size=(10, 10), strides=(2, 2),\n",
        "              input_shape=input_shape))\n",
        "    self.model.add(Activation('relu'))\n",
        "    self.model.add(MaxPooling2D(2, 2))\n",
        "    ## ********* Classification layer\n",
        "    self.model.add(Flatten())\n",
        "    self.model.add(Dense(128, activation='relu'))\n",
        "    self.model.add(Dense(num_classes, activation='softmax'))\n",
        "    self.model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer='adam',\n",
        "                      metrics=['categorical_accuracy'])\n",
        "\n",
        "def HP_Tuning_model_1D(dense_layer_sizes, filters, kernel_size):\n",
        "  x_train = x_train_HP.reshape(x_train_HP.shape[0], img_rows_33, img_cols_33, 1)\n",
        "  x_test = x_test_HP.reshape(x_test_HP.shape[0], img_rows_33, img_cols_33, 1)\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "\n",
        "  img_rows, img_cols = len(x_test[0]), len(x_test[0][0])\n",
        "  num_classes = len(y_train_HP[0])\n",
        "  input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "  model = Sequential()\n",
        "  ## *********** First layer Conv\n",
        "  model.add(Conv2D(filters, kernel_size=kernel_size, strides=(1, 1),\n",
        "                     input_shape=input_shape))\n",
        "  # model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  # model.add(LeakyReLU())\n",
        "  model.add(MaxPooling2D(1, 2))\n",
        "  model.output_shape\n",
        "\n",
        "  ## ********* Classification layer\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(dense_layer_sizes, activation='relu'))\n",
        "\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  #model.output_shape\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['categorical_accuracy'])\n",
        "  #model.summary()\n",
        "  return model\n",
        "\n",
        "def HP_Tuning_model_Vanilla(dense_layer_sizes, filters, stride, kernel_size):\n",
        "  x_train = x_train_HP.reshape(x_train_HP.shape[0], img_rows_33, img_cols_33, 1)\n",
        "  x_test = x_test_HP.reshape(x_test_HP.shape[0], img_rows_33, img_cols_33, 1)\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "\n",
        "  img_rows, img_cols = len(x_test[0]), len(x_test[0][0])\n",
        "  num_classes = len(y_train_HP[0])\n",
        "  input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "  model = Sequential()\n",
        "  ## *********** First layer Conv\n",
        "  model.add(Conv2D(filters, kernel_size=kernel_size, strides=stride,\n",
        "                    input_shape=input_shape))\n",
        "  # model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  # model.add(LeakyReLU())\n",
        "  model.add(MaxPooling2D(2, 2))\n",
        "  model.output_shape\n",
        "\n",
        "  ## ********* Classification layer\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(dense_layer_sizes, activation='relu'))\n",
        "\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  model.output_shape\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['categorical_accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "gBdVZoTvsSFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation\n",
        "\n",
        "For training with 33 classes, the 1D-CNN requires 2218529 parameters to be tuned during training, 2D-Vanilla-CNN requires 5721537 parameters to be tuned, Hybrid-CNN requires 362177 parameters to be tuned.\n",
        "\n",
        "For training with 33 classes plus the normal class, the 1D-CNN requires 211618 parameters to be tuned during training, 2D-Vanilla-CNN requires 1420866 parameters to be tuned, Hybrid-CNN requires 362306 parameters to be tuned. The normal class is added to take the impact of tissue of origin into account. A new label was introduced in the prediction layer, where it takes all normal samples (regardless of their original tissue type designation). The overall accuracy of the models with the introduction of the normal class is sligtly lower due to the presence of the normal samples.\n",
        "\n",
        "For evaluation categorical accuracy was used as the metric for comparing models."
      ],
      "metadata": {
        "id": "by75_9ns_j-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters\n",
        "\n",
        "The hyperparameters were tuned using Grid Search method. The hyperparameters tuned were the dense layer size, number and size of kernels, and the stride of kernels.\n",
        "\n",
        "The hyperparameter tuning code provided in the original paper's github is incompatible due to the removal of KerasClassifier from the sklearn package. To use KerasClassifier, you need to install the latest version of sklearn and scikeras, but this breaks the code when using OneHotEncoder when preprocessing the data.\n",
        "\n",
        "The original paper uses 25 epochs, so this would take a very long time to run anyways, so it is not practical to actually tune the hyperparameters in this environment and not needed for this paper reproduction. I will just use the hyperparamters given by the original paper after they ran the hyperparameter tuning code.\n"
      ],
      "metadata": {
        "id": "EghYO2muJKxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This will not run because it requires KerasClassifier from latest version of sklearn, which breaks the OneHotEncoder.\n",
        "'''\n",
        "dense_size_candidates = [64, 128, 512]\n",
        "my_classifier = KerasClassifier(HP_Tuning_model_1D, batch_size=128)\n",
        "validator = GridSearchCV(my_classifier,\n",
        "                         param_grid={'dense_layer_sizes': dense_size_candidates,\n",
        "                                     # epochs is avail for tuning even when not\n",
        "                                     # an argument to model building function\n",
        "                                     'epochs': [25],\n",
        "                                     'filters': [8,16, 32, 64],\n",
        "                                     'kernel_size': [(1, 71)]},\n",
        "                         scoring='neg_log_loss',\n",
        "                         n_jobs=1)\n",
        "validator.fit(x_train, y_train)\n",
        "\n",
        "print('The parameters of the best model for 1D-CNN 33 Class are: ')\n",
        "print(validator.best_params_)\n",
        "\n",
        "dense_size_candidates = [64, 128, 512]\n",
        "my_classifier = KerasClassifier(HP_Tuning_model_Vanilla, batch_size=128)\n",
        "validator = GridSearchCV(my_classifier,\n",
        "                         param_grid={'dense_layer_sizes': dense_size_candidates,\n",
        "                                     # epochs is avail for tuning even when not\n",
        "                                     # an argument to model building function\n",
        "                                     'epochs': [25],\n",
        "                                     'filters': [8, 16, 32, 64], 'stride': [(1, 1),(2, 2),(5, 5)],\n",
        "                                     'kernel_size': [(7, 7), (10, 10), (15, 15), (20, 20)]},\n",
        "                         scoring='neg_log_loss',\n",
        "                         n_jobs=1)\n",
        "validator.fit(x_train, y_train)\n",
        "\n",
        "print('The parameters of the best model for 2D-Vanilla-CNN 33 Class are: ')\n",
        "print(validator.best_params_)\n",
        "'''"
      ],
      "metadata": {
        "id": "23WcFwDQJiyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computational Requirements\n",
        "\n",
        "For my reproduction, the total runtime for the 33 class case is 724 s and 181 s for the 34 class case. For the 33 class case, average runtime for the 1D-CNN is 33 s, average runtime for the 2D-Vanilla is 101 s, average runtime for the Hybrid-CNN is 8 s. For the 34 class case, average runtime for the 1D-CNN is 4 s, average runtime for the 2D-Vanilla is 23 s, average runtime for the Hybrid-CNN is 7 s. The number of training epochs is 1, total number of trials is 1, type of hardware used is the Python 3 Google Compute Engine provided by Google Colab.\n",
        "\n",
        "In the original paper the total runtime is 80.3 seconds for the 1D-CNN, 94 seconds for the 2D-Vanilla-CNN, 80.8 seconds for the 2D-Hybrid-CNN. The number of training epochs is 20, total number of trials is 10, and the type of hardware used is a Linux server with Xeon 8176 CPU @2.1GHz, with 4 × 28 cores\n",
        "\n"
      ],
      "metadata": {
        "id": "Uh0nih6RNtkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "mRRYsVmcJSz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the 3 models for 33 class\n",
        "batch_size = 128\n",
        "epochs = 1\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "cvscores_1D_33 = []\n",
        "cvscores_Vanilla_33 = []\n",
        "cvscores_Hybrid_33 = []\n",
        "times_1D = []\n",
        "times_vanilla = []\n",
        "times_hybrid = []\n",
        "total_time = 0\n",
        "\n",
        "start_time = time.time()\n",
        "# model training loop: it is better to print the training/validation losses during the training\n",
        "for j in range(1):\n",
        "  i = 0\n",
        "  for train, test in kfold.split(input_Xs_33, y_s_33):\n",
        "    input_Xs = input_Xs_33.reshape(input_Xs_33.shape[0], img_rows_33, img_cols_33, 1)\n",
        "    input_shape = (img_rows_33, img_cols_33, 1)\n",
        "    input_Xs = input_Xs.astype('float32')\n",
        "\n",
        "    # for the hybrid CNN 33 class, input cols and rows dimensions are flipped\n",
        "    input_Xs_hybrid = input_Xs_33.reshape(input_Xs_33.shape[0], img_rows_hyb_33, img_cols_hyb_33, 1)\n",
        "    input_shape_hybrid = (img_cols_33, img_rows_33, 1)\n",
        "    input_img = Input(input_shape_hybrid)\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    integer_encoded = label_encoder.fit_transform(y_s_33)\n",
        "    # binary encode\n",
        "    onehot_encoder = OneHotEncoder(sparse=False)\n",
        "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "    num_classes = len(onehot_encoded[0])\n",
        "\n",
        "    # initialize models\n",
        "    OneD_CNN = One_CNN(input_shape, num_classes_33)\n",
        "    Vanilla_2D_CNN = Vanilla_33(input_shape, num_classes_33)\n",
        "    Hybrid_CNN = Hybrid(input_img, num_classes_33)\n",
        "    callbacks = [EarlyStopping(monitor='categorical_accuracy', patience=3, verbose=0)]\n",
        "\n",
        "    if i==0:\n",
        "      OneD_CNN.model.summary()\n",
        "      Vanilla_2D_CNN.model.summary()\n",
        "      Hybrid_CNN.model.summary()\n",
        "      i = i + 1\n",
        "\n",
        "    start_time_1D = time.time()\n",
        "    # Train 1D CNN 33 class\n",
        "    history_OneD = OneD_CNN.model.fit(input_Xs[train], onehot_encoded[train],\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        verbose=0, callbacks=callbacks, validation_data=(input_Xs[test], onehot_encoded[test]))\n",
        "    scores_oneD = OneD_CNN.model.evaluate(input_Xs[test], onehot_encoded[test], verbose=0)\n",
        "    print(\"1D CNN 33 Class %s: %.2f%%\" % ( OneD_CNN.model.metrics_names[1], scores_oneD[1]*100))\n",
        "    cvscores_1D_33.append(scores_oneD[1] * 100)\n",
        "    times_1D.append(time.time() - start_time_1D)\n",
        "\n",
        "    start_time_vanilla = time.time()\n",
        "    # Train 2D Vanilla CNN 33 class\n",
        "    history_Vanilla = Vanilla_2D_CNN.model.fit(input_Xs[train], onehot_encoded[train],\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        verbose=0, callbacks=callbacks, validation_data=(input_Xs[test], onehot_encoded[test]))\n",
        "    scores_vanilla = Vanilla_2D_CNN.model.evaluate(input_Xs[test], onehot_encoded[test], verbose=0)\n",
        "    print(\"Vanilla 2d CNN 33 Class %s: %.2f%%\" % (Vanilla_2D_CNN.model.metrics_names[1], scores_vanilla[1]*100))\n",
        "    cvscores_Vanilla_33.append(scores_vanilla[1] * 100)\n",
        "    times_vanilla.append(time.time() - start_time_vanilla)\n",
        "\n",
        "    start_time_hybrid = time.time()\n",
        "    # Train Hybrid CNN 33 Class\n",
        "    history_Hybrid = Hybrid_CNN.model.fit(input_Xs_hybrid[train], onehot_encoded[train],\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        verbose=0, callbacks=callbacks, validation_data=(input_Xs_hybrid[test], onehot_encoded[test]))\n",
        "    scores_hybrid = Hybrid_CNN.model.evaluate(input_Xs_hybrid[test], onehot_encoded[test], verbose=0)\n",
        "    print(\"Hybrid CNN 33 Class %s: %.2f%%\" % (Hybrid_CNN.model.metrics_names[1], scores_hybrid[1]*100))\n",
        "    cvscores_Hybrid_33.append(scores_hybrid[1] * 100)\n",
        "    times_hybrid.append(time.time() - start_time_hybrid)\n",
        "\n",
        "avg_1D_time = sum(times_1D) / len(times_1D)\n",
        "avg_vanilla_time = sum(times_vanilla) / len(times_vanilla)\n",
        "avg_hybrid_time = sum(times_hybrid) / len(times_hybrid)\n",
        "total_time = time.time() - start_time\n",
        "print(\"avg 1D 33 class training time: %d\" % avg_1D_time)\n",
        "print(\"avg Vanilla 33 class training time: %d\" % avg_vanilla_time)\n",
        "print(\"avg Hybrid 33 class training time: %d\" % avg_hybrid_time)\n",
        "print(\"total training time: %d\" % total_time)\n"
      ],
      "metadata": {
        "id": "gLZC-auG8jIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the 3 models for 34 class\n",
        "batch_size = 128\n",
        "epochs = 1\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "cvscores_1D = []\n",
        "cv_yscores_1D = []\n",
        "Y_test_1D = []\n",
        "\n",
        "cvscores_vanilla = []\n",
        "cv_yscores_vanilla = []\n",
        "Y_test_vanilla = []\n",
        "\n",
        "cvscores_hybrid = []\n",
        "cv_yscores_hybrid = []\n",
        "Y_test_hybrid = []\n",
        "\n",
        "times_1D_34 = []\n",
        "times_vanilla_34 = []\n",
        "times_hybrid_34 = []\n",
        "total_time_34 = 0\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(y_s_34)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "\n",
        "i = 0\n",
        "start_time = time.time()\n",
        "for train, test in kfold.split(X_cancer_samples_34, y_s_34):   # input_Xs in normal case and shuffled should be shuffled_Xs\n",
        "  input_Xs = input_Xs_34.reshape(input_Xs_34.shape[0], img_rows_34, img_cols_34, 1)\n",
        "  input_shape = (img_rows_34, img_cols_34, 1)\n",
        "  input_Xs = input_Xs.astype('float32')\n",
        "\n",
        "  # for the hybrid model\n",
        "  input_img = Input(input_shape)\n",
        "\n",
        "  num_classes = len(onehot_encoded[0])\n",
        "\n",
        "  # initialize models\n",
        "  OneD_CNN_34 = One_CNN(input_shape, num_classes)\n",
        "  Vanilla_2D_CNN_34 = Vanilla_34(input_shape, num_classes)\n",
        "  Hybrid_CNN_34 = Hybrid(input_img, num_classes)\n",
        "  callbacks = [EarlyStopping(monitor='categorical_accuracy', patience=3, verbose=0)]\n",
        "  if i==0:\n",
        "    OneD_CNN_34.model.summary()\n",
        "    Vanilla_2D_CNN_34.model.summary()\n",
        "    Hybrid_CNN_34.model.summary()\n",
        "    i = i + 1\n",
        "\n",
        "  start_time_1D = time.time()\n",
        "  # Train 1D CNN 34 class\n",
        "  history_OneD = OneD_CNN_34.model.fit(input_Xs[train], onehot_encoded[train],\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      verbose=0, callbacks=callbacks, validation_data=(input_Xs[test], onehot_encoded[test]))\n",
        "  scores_oneD = OneD_CNN_34.model.evaluate(input_Xs[test], onehot_encoded[test], verbose=0)\n",
        "  y_score_1D = OneD_CNN_34.model.predict(input_Xs[test])\n",
        "  print(\"1D CNN 34 Class %s: %.2f%%\" % ( OneD_CNN_34.model.metrics_names[1], scores_oneD[1]*100))\n",
        "  times_1D_34.append(time.time() - start_time_1D)\n",
        "\n",
        "  cvscores_1D.append(scores_oneD[1] * 100)\n",
        "  #Y_test_1D.append(onehot_encoded[test])\n",
        "  #cv_yscores_1D.append(y_score_1D)\n",
        "\n",
        "  start_time_vanilla = time.time()\n",
        "  # Train 2D Vanilla CNN 34 class\n",
        "  history_Vanilla = Vanilla_2D_CNN_34.model.fit(input_Xs[train], onehot_encoded[train],\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      verbose=0, callbacks=callbacks, validation_data=(input_Xs[test], onehot_encoded[test]))\n",
        "  scores_vanilla_34 = Vanilla_2D_CNN_34 .model.evaluate(input_Xs[test], onehot_encoded[test], verbose=0)\n",
        "  y_score_vanilla = Vanilla_2D_CNN_34 .model.predict(input_Xs[test])\n",
        "  print(\"Vanilla_2D_CNN_34  %s: %.2f%%\" % ( Vanilla_2D_CNN_34 .model.metrics_names[1], scores_vanilla_34[1]*100))\n",
        "  times_vanilla_34.append(time.time() - start_time_vanilla)\n",
        "\n",
        "  cvscores_vanilla.append(scores_vanilla_34[1] * 100)\n",
        "  #Y_test_vanilla.append(onehot_encoded[test])\n",
        "  #cv_yscores_vanilla.append(y_score_vanilla)\n",
        "\n",
        "  start_time_hybrid = time.time()\n",
        "  # Train Hybrid CNN 34 Class\n",
        "  history_Hybrid = Hybrid_CNN_34.model.fit(input_Xs[train], onehot_encoded[train],\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      verbose=0, callbacks=callbacks, validation_data=(input_Xs[test], onehot_encoded[test]))\n",
        "  scores_hybrid = Hybrid_CNN_34.model.evaluate(input_Xs[test], onehot_encoded[test], verbose=0)\n",
        "  print(\"Hybrid CNN 34 Class %s: %.2f%%\" % (Hybrid_CNN_34.model.metrics_names[1], scores_hybrid[1]*100))\n",
        "  times_hybrid_34.append(time.time() - start_time_hybrid)\n",
        "\n",
        "  cvscores_hybrid.append(scores_hybrid[1] * 100)\n",
        "\n",
        "avg_1D_time_34 = sum(times_1D_34) / len(times_1D_34)\n",
        "avg_vanilla_time_34 = sum(times_vanilla_34) / len(times_vanilla_34)\n",
        "avg_hybrid_time_34 = sum(times_hybrid_34) / len(times_hybrid_34)\n",
        "total_time_34 = time.time() - start_time\n",
        "print(\"avg 1D 34 class training time: %d\" % avg_1D_time_34)\n",
        "print(\"avg Vanilla 34 class training time: %d\" % avg_vanilla_time_34)\n",
        "print(\"avg Hybrid 34 class training time: %d\" % avg_hybrid_time_34)\n",
        "print(\"total training time: %d\" % total_time_34)\n"
      ],
      "metadata": {
        "id": "Pfuyxs2aDCd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation and Results\n",
        "The metrics the original paper used to evaluate the models were accuracy and training loss. Since, I only used 1 epoch, it did not make sense to keep track of loss over epochs. So, in my reproduction, I only used accuracy to evaluate the models.\n"
      ],
      "metadata": {
        "id": "gX6bCcZNuxmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics to evaluate my model\n",
        "cvscores_1D_33_mean = np.mean(cvscores_1D_33)\n",
        "cvscores_vanilla_33_mean = np.mean(cvscores_Vanilla_33)\n",
        "cvscores_hybrid_33_mean = np.mean(cvscores_Hybrid_33)\n",
        "print(\"1D CNN 33 class Mean Categorical Accuracy: %.2f%% (+/- %.2f%%)\" % (cvscores_1D_33_mean, np.std(cvscores_1D_33)))\n",
        "print(\"Vanilla 2D CNN 33 class Mean  Categorical Accuracy: %.2f%% (+/- %.2f%%)\" % (cvscores_vanilla_33_mean, np.std(cvscores_Vanilla_33)))\n",
        "print(\"Hybrid CNN 33 class Mean Categorical Accuracy: %.2f%% (+/- %.2f%%)\" % (cvscores_hybrid_33_mean, np.std(cvscores_Hybrid_33)))\n",
        "\n",
        "cvscores_1D_34_mean = np.mean(cvscores_1D)\n",
        "cvscores_vanilla_34_mean = np.mean(cvscores_vanilla)\n",
        "cvscores_hybrid_34_mean = np.mean(cvscores_hybrid)\n",
        "print(\"1D CNN 34 Class mean Categorical Accuracy: %.2f%% (+/- %.2f%%)\" % (cvscores_1D_34_mean, np.std(cvscores_1D)))\n",
        "print(\"Vanilla 2D CNN 34 Class mean Categorical Accuracy: %.2f%% (+/- %.2f%%)\" % (cvscores_vanilla_34_mean, np.std(cvscores_vanilla)))\n",
        "print(\"Hybrid CNN 34 Class mean Categorical Accuracy: %.2f%% (+/- %.2f%%)\" % (cvscores_hybrid_34_mean, np.std(cvscores_hybrid)))\n",
        "\n",
        "# plot to compare categorical accuracy\n",
        "# set width of bar\n",
        "barWidth = 0.25\n",
        "fig = plt.subplots(figsize =(12, 8))\n",
        "\n",
        "# heights of bars\n",
        "class_33 = [cvscores_1D_33_mean, cvscores_vanilla_33_mean, cvscores_hybrid_33_mean]\n",
        "class_34 = [cvscores_1D_34_mean, cvscores_vanilla_34_mean, cvscores_hybrid_34_mean]\n",
        "\n",
        "# Set position of bar on X axis\n",
        "br1 = np.arange(len(class_33))\n",
        "br2 = [x + barWidth for x in br1]\n",
        "\n",
        "# Make the plot\n",
        "plt.bar(br1, class_33, color ='b', width = barWidth,\n",
        "        edgecolor ='grey', label ='33 Cancer Types')\n",
        "plt.bar(br2, class_34, color ='y', width = barWidth,\n",
        "        edgecolor ='grey', label ='33 Cancer Types + Normal')\n",
        "\n",
        "# Adding Xticks\n",
        "plt.title('Model Accuracies for 33 and 34 Class')\n",
        "plt.ylabel('Mean Accuracy', fontweight ='bold', fontsize = 15)\n",
        "plt.xticks([r + barWidth for r in range(len(class_33))],\n",
        "        ['1D-CNN', '2D-Vanilla-CNN', '2D-Hybrid-CNN'])\n",
        "plt.ylim(ymin=70)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "#plt.savefig('Accuracy_Results.png')\n",
        "\n",
        "# it is better to save the numbers and figures for your presentation."
      ],
      "metadata": {
        "id": "LjW9bCkouv8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model comparison (Results and Analysis and Ablation Study)\n",
        "\n",
        "The original paper also trained a 2D-3Layer CNN as a baseline to compare the three models created in this paper against, but this baseline model was not included in the codebase. The 2D-3Layer CNN has significantly more parameters to train (the paper reported 26,211,233 parameters), resulting in a much longer time to train the model compared to the three models proposed in this paper.\n",
        "\n",
        "Since I only ran the three proposed model in the paper with 1 epoch, my performance metrics will not compare to those in the paper. But, I can still compare the three models' metrics I reproduced against each other.\n",
        "\n",
        "When trained with only the 33 cancer types, the 1D-CNN slightly outperformed the other two models with a mean accuracy of 90.51% compared to 89.1% and 89.87% of the Vanilla-CNN and the Hybrid-CNN respectively. When trained with the 33 cancer types plus the normal, the Hybrid-CNN outperformed the other two models with a mean accuracy of 89.43% compared to 86.79% and 87.31% of the 1D-CNN and Vanilla-CNN respectively. These number confirm that hypothesis 1 is true, that the three models proposed in the paper can achieve sufficient and comparable accuracy numbers to more complicated models.\n",
        "\n",
        "Since, these number are all relatively close to each other, the simpler model with less parameters to train would be preferred. This would be the 1D-CNN or the Hybrid-CNN. The Hybrid-CNN performs better than the 1D-CNN in the 33 class plus normal dataset and performs similarly to the 1D-CNN in the 33 class dataset, but the Hybrid-CNN also has more parameters that need to be trained than the 1D-CNN. Also, in the original paper, the performance of the 1D-CNN was a lot closer to the Hybrid-CNN in the 33 class plus normal case, so it makes sense why the paper preferred the 1D-CNN as well.\n",
        "\n",
        "Also when the normal samples were introduced, thus introducing the impact of tissue of origin to the models, the model accuracies were all lower compared to using only the 33 cancer types. But, the accuracies numbers were not significantly lower, the largest discrepancy in my reproduction being the 1D-CNN performance of 86.79% accuracy with normal samples compared to 90.51% without normal samples. This difference of 3.72% accuracy is not a large difference, so that means these three models are robust enough to handle the impact of tissue of origin. These results conclude that hypothesis 2 is true, these three models are robust enough to be able to take tissue of origin into account when predicting cancer types. Also, consider that in the original paper, with more epochs, the accuracy difference between the 33 class and the 33 plus normal class is even smaller.\n",
        "\n",
        "My ablation study that I propsed was to compare the three simpler models proposed in the paper with a more complicated 2D-3Layer CNN. In my reproduction, the three simple models had accuracy metrics above 90% even when I only used 1 epoch. The paper's github did not contain code for the 2D-3Layer CNN, so I was not able to reproduce the 2D-3Layer model and the accuracy metrics for that model. But by going off the numbers in the original paper for the 2D-3Layer model they implemented, I am still able to compare my results in my reproduction (>90% accuracy) to the accuracy of the 2D-3Layer model results in the original paper (~95%), which shows that the three simple models that I trained are only 5% lower in accuracy to the 2D-3Layer model (also note that I trained with epoch of 1, so the actual gap should be even smaller, which is shown in the original paper).\n"
      ],
      "metadata": {
        "id": "8EAWAy_LwHlV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion\n",
        "\n",
        "The Paper is reproducible, but the model training takes too much time, which is why I reduced the epochs to 1, so I was not able to replicate the exact accuracy numbers that the original paper reported.\n",
        "\n",
        "I found that getting the paper's code to run was easy, there were little bugs, just a couple of typos that I found. The only issue was with the hyperparameter training, the original paper used KerasClassifier, which is no longer in the sklearn package. I had to update to the latest sklearn package and use the scikeras package to be able to use KerasClassifier. But when I updated to the latest sklearn package, that broke the preprocessing code that used OneHotEncoder. So, I decided to not try to replicate the results of the hyperparameter training, but the hyperparameter training would take too long anyways, so there is not a lot to be gained by trying to repliate that in my paper. The main goal of the original paper was to evaluate the three models, and I was able to do that by using the optimal hyperparamters given by the original paper.\n",
        "\n",
        "I found that organizing the paper's code was difficult. The paper has separate files for training each model, but there is a lot of duplicate code in each file. So it was difficult to condense the codebase into more structured and less duplicated code. For example using classes for the models and functions for getting the data. I found there were slight differences in the processing of the data in the Hybrid-CNN 33 class code compared to the 1D-CNN and Vanilla-CNN 33 class code. So I had to make slight adjustments in my code to account for that.\n",
        "\n",
        "I would suggest to the author and other reproducers to make the codebase more readable and organized by introducing classes and functions. This will also remove replicated code in each of the files in the original codebase.\n",
        "\n",
        "In the next phase or future, I would try to first replicate the original paper's accuracy metrics by using the original epoch numbers that the original paper used. Also, I may try using these 3 models with other data from The Cancer Genome Atlas to see how robust the models are."
      ],
      "metadata": {
        "id": "qH75TNU71eRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "1.   Mostavi, M., Chiu, YC., Huang, Y. et al. Convolutional neural network models for cancer type prediction based on gene expression. BMC Med Genomics 13 (Suppl 5), 44 (2020). https://doi.org/10.1186/s12920-020-0677-2\n",
        "2. Mostavi, M., CNNCancerType, (2020), GitHub repository, https://github.com/MMostavi/CNNCancerType\n",
        "\n"
      ],
      "metadata": {
        "id": "SHMI2chl9omn"
      }
    }
  ]
}